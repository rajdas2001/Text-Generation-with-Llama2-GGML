# Text-Generation-with-Llama2-GGML

## Introduction
![Llama](https://github.com/rajdas2001/Text-Generation-with-Llama2-GGML/blob/main/llama.jpg)
Model Used: https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML

1. Built on the Llama2 GGML model, this repository contains the code for a text generation model. Llama 2 is a pre-trained model with significant improvements over the Llama 1 models, including being trained on 40% more tokens, having a much longer context length (4k tokens), and using grouped-query attention.
2. This model can be used for creating essays, social media posts, poems, song lyrics etc.
3. One of the most significant advantages of employing GGML for quantization lies in its ability to facilitate efficient model compression while simultaneously upholding high performance standards and reducing memory footprint.


## Dependencies
1. Python==3.9.13
2. ctransformers==0.2.27
3. langchain==0.1.6


